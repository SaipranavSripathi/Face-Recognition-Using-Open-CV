{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read images\n",
    "#source,0--->for gray scale\n",
    "#you can use ur own paths here\n",
    "img1=cv2.imread(\"C:/Users/prana/OneDrive/Desktop/projects/OPEN-CV/training_data/20200313093834_IMG_9535.jpg\",0)\n",
    "img2=cv2.imread(\"C:/Users/prana/OneDrive/Desktop/projects/OPEN-CV/training_data/20200313093934_IMG_9536.jpg\",0)\n",
    "img1=cv2.resize(img1,(600,600))\n",
    "img2=cv2.resize(img2,(600,600))\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image1\",img1)\n",
    "cv2.imshow(\"Image2\",img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating detector ORB-->oriented fast and rotated brief\n",
    "#it defaultly detects 500 features generally for any image\n",
    "#ORB uses a modified version of fast algorithm called oriented fast algorithm\n",
    "#ORB is free and fast version else swift/surf detectors are patented and not free\n",
    "\n",
    "orb=cv2.ORB_create(nfeatures=1000) #if nothing mentioned its 500\n",
    "\n",
    "#kp's are the keypoints to identify a specific feature\n",
    "#des's are the descriptors --->describing the image in terms of numbers array-->(500,32) always size\n",
    "#i,e 500 features default and each feature is described with 32 values\n",
    "\n",
    "kp1,des1=orb.detectAndCompute(img1,None) #image and mask\n",
    "kp2,des2=orb.detectAndCompute(img2,None) #image and mask\n",
    "\n",
    "#drawing keypoints detected\n",
    "\n",
    "imgKp1=cv2.drawKeypoints(img1,kp1,None)\n",
    "imgKp2=cv2.drawKeypoints(img2,kp2,None)\n",
    "\n",
    "cv2.imshow(\"Image1 with keypoints\",imgKp1)\n",
    "cv2.imshow(\"Image2 with keypoints2\",imgKp2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using matchers to match the descriptors as both are of the particularly same images\n",
    "#matchers match every des of one to other\n",
    "#the other technique is k nearest technique-->here used\n",
    "\n",
    "bf=cv2.BFMatcher()\n",
    "matches=bf.knnMatch(des1,des2,k=2) #k=2-->2 values to compare\n",
    "\n",
    "#deciding whether a match is a good match/not\n",
    "good_match=[]\n",
    "for i,j in matches :\n",
    "    if i.distance<0.75*j.distance :\n",
    "        good_match.append([i])#append if distance is less\n",
    "print(len(good_match))\n",
    "imgMatches=cv2.drawMatchesKnn(img1,kp1,img2,kp2,good_match,None,flags=2)\n",
    "cv2.imshow(\"Matches\",imgMatches)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image classifier\n",
    "#using feature detectors\n",
    "#generic code for clases and each image\n",
    "#we use os-lib for this\n",
    "\n",
    "#storing path for each image\n",
    "path='C:/Users/prana/OneDrive/Desktop/projects/OPEN-CV/training_data'\n",
    "#to classify images w.r.to classes 2 lists\n",
    "images=[]\n",
    "classnames=[]\n",
    "mylist=os.listdir(path)\n",
    "#print(mylist) #gives images names ---> always give a unique image for a specific identification\n",
    "#hence len(mylist) gives num,ber of classes\n",
    "\n",
    "for i in mylist :\n",
    "    imgCurr=cv2.imread(path+'/'+i,0)\n",
    "    imgCurr=cv2.resize(imgCurr,(500,500))\n",
    "    images.append(imgCurr)\n",
    "    classnames.append(i.split('.')[0])\n",
    "#print(classnames)\n",
    "\n",
    "#function takes list of images and creates descriptors for eaxh and store them\n",
    "orb=cv2.ORB_create(nfeatures=1000) #if nothing mentioned its 500\n",
    "kpList=[]\n",
    "def findDes(images) :\n",
    "    desList=[]\n",
    "    for i in images :\n",
    "        kp,des=orb.detectAndCompute(i,None)\n",
    "        desList.append(des)\n",
    "        kpList.append(kp)\n",
    "    return desList\n",
    "\n",
    "desList=findDes(images)\n",
    "#print(len(desList)) #--->number of images\n",
    "\n",
    "#function to find des for the captured image\n",
    "def findID(img,desList) :\n",
    "    kp2,des2=orb.detectAndCompute(img,None)\n",
    "    #finding matches\n",
    "    matchList=[] #for storing all achieving good matches\n",
    "    \n",
    "    finalval=-1 #for the label to be printed\n",
    "    \n",
    "    bf=cv2.BFMatcher()\n",
    "    \n",
    "    #matching each descriptor from desList to des2\n",
    "    try:\n",
    "        for des1 in desList :\n",
    "    \n",
    "            matches=bf.knnMatch(des1,des2,k=2) #k=2-->2 values to compare\n",
    "            #deciding whether a match is a good match/not\n",
    "            good_match=[]\n",
    "            for i,j in matches :\n",
    "                if i.distance<0.75*j.distance :\n",
    "                    good_match.append([i])#append if distance is less\n",
    "            #imgMatches=cv2.drawMatchesKnn(images[desList.index(des1)],kpList[desList.index(des1)],img,kp2,good_match,None,flags=2)\n",
    "            #cv2.show(\"matching\",imgMatches)\n",
    "            #cv2.waitKey(0)\n",
    "            matchList.append(len(good_match)) #no of good matches for each of the images\n",
    "        print(matchList)\n",
    "    #try except-->if no match\n",
    "    except :\n",
    "        pass\n",
    "    threashhold=5 #usual threashold\n",
    "    if len(matchList)!=0 :\n",
    "        if max(matchList)>=threashhold :\n",
    "            finalval=matchList.index(max(matchList))\n",
    "    return finalval\n",
    "#--------------->TESTING<----------------#        \n",
    "#getting camera feed to detect\n",
    "#cap=cv2.VideoCapture(0)\n",
    "\n",
    "#defining while to read images from webcam\n",
    "#while True :\n",
    "#    success,img2=cap.read()\n",
    "#    imgOriginal=img2.copy()\n",
    "#    img2=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "#    cv2.imshow(\"Image\",img2)\n",
    "#    cv2.waitKey(0)\n",
    "#not using webcam because of webcam troubles\n",
    "        \n",
    "#storing path for each image\n",
    "path='C:/Users/prana/OneDrive/Desktop/projects/OPEN-CV/testing_data'\n",
    "#to classify images w.r.to classes 2 lists\n",
    "mylist=os.listdir(path)\n",
    "#print(mylist) #gives images names ---> always give a unique image for a specific identification\n",
    "#hence len(mylist) gives num,ber of classes\n",
    "print(mylist)\n",
    "c=0\n",
    "for i in mylist :\n",
    "    imgCurr=cv2.imread(path+'/'+i,0)\n",
    "    imgCurr=cv2.resize(imgCurr,(500,500))\n",
    "    c+=1\n",
    "    print(\"Image number\",c)\n",
    "    index=findID(imgCurr,desList)\n",
    "    if index!=-1 :\n",
    "        print(index)\n",
    "        cv2.putText(imgCurr,classnames[index],(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,255),1)\n",
    "    else :\n",
    "        print(index)\n",
    "        cv2.putText(imgCurr,\"Not detected\",(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,255),1)\n",
    "    cv2.imshow(\"DETECTION\",imgCurr)\n",
    "    #plt.imshow(imgCurr,cmap='gray')\n",
    "    print()\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
